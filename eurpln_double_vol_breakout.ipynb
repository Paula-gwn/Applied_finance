{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34d52adb",
   "metadata": {},
   "source": [
    "# EUR/PLN Tick Strategy — Double Volatility Breakout (EGARCH‑adaptive)\n",
    "**Author:** <your name>\n",
    "\n",
    "**Data window:** 2025‑09‑01 00:00:00 to 2025‑10‑06 00:00:00 (tick‑by‑tick)\n",
    "\n",
    "**Out‑of‑sample evaluation:** 2025‑09‑22 00:00:00 to 2025‑10‑06 00:00:00\n",
    "\n",
    "**Goal:** Build a technically correct, relatively original, and profitable strategy on the OOS window, using tools from the course.\n",
    "\n",
    "> Tip: keep parameters ≤5 to curb data‑snooping. Add rich comments explaining each choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e809fd1f",
   "metadata": {},
   "source": [
    "## 0. Project requirements (checklist)\n",
    "- Download tick EUR/PLN data for the full window\n",
    "- Implement strategy and backtest with transaction costs\n",
    "- Report **gross/net P&L** and **Sharpe ratio** on the OOS window\n",
    "- Provide concise email‑body bullets with the strategy idea & metrics\n",
    "- Ensure no look‑ahead, minimize biases; keep parameters simple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f862f82e",
   "metadata": {},
   "source": [
    "## 1. Environment & packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5dd5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Recommended: create a dedicated virtual env before running locally.\n",
    "# Install as needed:\n",
    "# !pip install pandas numpy pyarrow polars==0.20.* plotly arch hmmlearn scikit-learn statsmodels nbformat pytz tzdata\n",
    "# Optional data helpers if you choose to pull from brokers:\n",
    "# !pip install dukascopy  # or 'dukascopy-trader', depending on package choice\n",
    "\n",
    "import os, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.width\", 120)\n",
    "pd.set_option(\"display.max_columns\", 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fee616b",
   "metadata": {},
   "source": [
    "## 2. Data download & loading\n",
    "Choose one source (free suggestions from class): **Dukascopy** or **TrueFX**. Save raw ticks (bid/ask if available). Keep a **parquet** copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3abdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "DATA_DIR = \"./data\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "START = pd.Timestamp('2025-09-01 00:00:00', tz='UTC')\n",
    "END   = pd.Timestamp('2025-10-06 00:00:00', tz='UTC')\n",
    "\n",
    "def load_ticks_from_parquet(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_parquet(path)\n",
    "    if \"ts\" not in df.columns:\n",
    "        raise ValueError(\"Expected 'ts' column in parquet.\")\n",
    "    df[\"ts\"] = pd.to_datetime(df[\"ts\"], utc=True)\n",
    "    df = df.sort_values(\"ts\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "PARQUET_PATH = os.path.join(DATA_DIR, \"eurpln_ticks.parquet\")\n",
    "if os.path.exists(PARQUET_PATH):\n",
    "    ticks = load_ticks_from_parquet(PARQUET_PATH)\n",
    "else:\n",
    "    # Dummy data so the template runs; replace with real data load.\n",
    "    rng = pd.date_range(START, END, freq=\"5min\", tz=\"UTC\", inclusive=\"left\")\n",
    "    mid = 4.5 + np.cumsum(np.random.normal(scale=0.0005, size=len(rng)))\n",
    "    spread = np.full(len(rng), 0.0004)  # 4 pips proxy\n",
    "    ticks = pd.DataFrame({\"ts\": rng, \"bid\": mid - spread/2, \"ask\": mid + spread/2})\n",
    "\n",
    "ticks.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c5f3fd",
   "metadata": {},
   "source": [
    "## 3. Cleaning & mid‑price series\n",
    "- Remove obvious outliers, non‑finite values\n",
    "- Create mid price; compute microstructure returns\n",
    "- (Optional) resample to **1s** bars for speed, keeping highest fidelity feasible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2390cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def basic_clean(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df = df.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    good = (df[\"ask\"] > df[\"bid\"]) & ((df[\"ask\"] - df[\"bid\"]) < 0.02)  # 2 grosze sanity\n",
    "    df = df.loc[good]\n",
    "    df[\"mid\"] = (df[\"bid\"] + df[\"ask\"]) / 2\n",
    "    return df\n",
    "\n",
    "ticks = basic_clean(ticks)\n",
    "s1 = (ticks.set_index(\"ts\")[[\"bid\",\"ask\",\"mid\"]]\n",
    "      .resample(\"1s\")\n",
    "      .last()\n",
    "      .dropna()\n",
    "      .reset_index())\n",
    "s1.rename(columns={\"ts\":\"time\"}, inplace=True)\n",
    "s1.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5e8484",
   "metadata": {},
   "source": [
    "## 4. Intraday seasonality filter (FX active hours)\n",
    "Filter to active overlap hours to reduce false signals (e.g., 07:00–18:00 Europe/Warsaw). Adjust if you prefer 24/5 trading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e168be00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pytz\n",
    "\n",
    "def warsaw_active_mask(ts: pd.Series) -> pd.Series:\n",
    "    tz = \"Europe/Warsaw\"\n",
    "    local = ts.dt.tz_convert(tz)\n",
    "    hours = local.dt.hour\n",
    "    return (hours >= 7) & (hours <= 18)\n",
    "\n",
    "s1[\"active\"] = warsaw_active_mask(s1[\"time\"])\n",
    "s1 = s1[s1[\"active\"]].drop(columns=[\"active\"]).reset_index(drop=True)\n",
    "s1.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecccb931",
   "metadata": {},
   "source": [
    "## 5. Volatility model\n",
    "- Compute short‑horizon realized volatility\n",
    "- Fit **EGARCH(1,1)** to mid‑returns (no look‑ahead) and forecast next‑step σ\n",
    "- Band = k × σ_forecast; use **double threshold** (entry/exit)\n",
    "\n",
    "*Note:* EGARCH expanding fits can be slow on dense data. You can speed this up by batching or using rolling windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b80560",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from arch import arch_model\n",
    "\n",
    "s1[\"ret\"] = np.log(s1[\"mid\"]).diff()\n",
    "s1 = s1.dropna().reset_index(drop=True)\n",
    "\n",
    "# Rolling realized volatility fallback\n",
    "s1[\"rv\"] = s1[\"ret\"].rolling(300, min_periods=60).std()\n",
    "\n",
    "def egarch_forecast_series(returns: pd.Series, start_idx: int) -> pd.Series:\n",
    "    \"\"\"Expanding EGARCH(1,1) forecast of next-step volatility; fallback to RV on failure.\"\"\"\n",
    "    sigmas = np.full(len(returns), np.nan, dtype=float)\n",
    "    for t in range(start_idx, len(returns)):\n",
    "        r_train = returns.iloc[:t]\n",
    "        try:\n",
    "            am = arch_model(r_train*100, vol=\"EGARCH\", p=1, o=0, q=1, mean=\"Zero\", dist=\"t\")\n",
    "            res = am.fit(disp=\"off\")\n",
    "            f = res.forecast(horizon=1, reindex=False)\n",
    "            sigmas[t] = float(f.variance.values[-1,0])**0.5 / 100.0\n",
    "        except Exception:\n",
    "            sigmas[t] = r_train.rolling(300, min_periods=60).std().iloc[-1]\n",
    "    return pd.Series(sigmas, index=returns.index)\n",
    "\n",
    "burn_in = 5000 if len(s1) > 6000 else max(300, int(len(s1)*0.1))\n",
    "s1[\"sigma\"] = egarch_forecast_series(s1[\"ret\"], start_idx=burn_in)\n",
    "s1[\"sigma\"].fillna(s1[\"rv\"], inplace=True)\n",
    "s1.dropna(inplace=True)\n",
    "s1.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44c730c",
   "metadata": {},
   "source": [
    "## 6. Double‑volatility breakout logic\n",
    "Signal = mid − EMA(mid). Entry bands: ± k_entry·σ; Exit bands: ± k_exit·σ (k_exit < k_entry). Momentum direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6f2497",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "span = 300  # ~5 min EMA at 1s sampling\n",
    "s1[\"ref\"] = s1[\"mid\"].ewm(span=span, adjust=False).mean()\n",
    "s1[\"signal\"] = s1[\"mid\"] - s1[\"ref\"]\n",
    "\n",
    "k_entry = 2.0\n",
    "k_exit  = 0.8\n",
    "\n",
    "N_year = 252*24*60*60\n",
    "target_vol_ann = 0.10\n",
    "def unit_risk(sigma):\n",
    "    return target_vol_ann / (sigma * math.sqrt(N_year) + 1e-8)\n",
    "\n",
    "s1[\"upper_entry\"] =  k_entry * s1[\"sigma\"]\n",
    "s1[\"lower_entry\"] = -k_entry * s1[\"sigma\"]\n",
    "s1[\"upper_exit\"]  =  k_exit  * s1[\"sigma\"]\n",
    "s1[\"lower_exit\"]  = -k_exit  * s1[\"sigma\"]\n",
    "\n",
    "pos = np.zeros(len(s1), dtype=float)\n",
    "size = np.zeros(len(s1), dtype=float)\n",
    "\n",
    "for i in range(1, len(s1)):\n",
    "    sig_prev = s1[\"signal\"].iat[i-1]\n",
    "    up_e = s1[\"upper_entry\"].iat[i-1]\n",
    "    lo_e = s1[\"lower_entry\"].iat[i-1]\n",
    "    up_x = s1[\"upper_exit\"].iat[i-1]\n",
    "    lo_x = s1[\"lower_exit\"].iat[i-1]\n",
    "    p_prev = pos[i-1]\n",
    "    if p_prev == 0:\n",
    "        if sig_prev > up_e:\n",
    "            pos[i] =  1\n",
    "        elif sig_prev < lo_e:\n",
    "            pos[i] = -1\n",
    "        else:\n",
    "            pos[i] = 0\n",
    "    elif p_prev > 0:\n",
    "        if sig_prev <= up_x:\n",
    "            pos[i] = 0\n",
    "        elif sig_prev < lo_e:\n",
    "            pos[i] = -1\n",
    "        else:\n",
    "            pos[i] = 1\n",
    "    else:  # p_prev < 0\n",
    "        if sig_prev >= lo_x:\n",
    "            pos[i] = 0\n",
    "        elif sig_prev > up_e:\n",
    "            pos[i] = 1\n",
    "        else:\n",
    "            pos[i] = -1\n",
    "    sigma_t = s1[\"sigma\"].iat[i-1]\n",
    "    size[i] = np.clip(unit_risk(sigma_t), 0, 10.0)\n",
    "\n",
    "s1[\"pos_dir\"] = pos\n",
    "s1[\"pos\"] = s1[\"pos_dir\"] * size\n",
    "s1.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc37dde",
   "metadata": {},
   "source": [
    "## 7. P&L with transaction costs and bid/ask\n",
    "- Trade on next tick, using bid/ask (market order assumption)\n",
    "- Transaction cost = half‑spread + commission (bps)\n",
    "- Compute **gross** and **net** P&L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1a7e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s1[\"pos_exec\"] = s1[\"pos\"].shift().fillna(0.0)\n",
    "\n",
    "delta_pos = s1[\"pos_exec\"].diff().fillna(s1[\"pos_exec\"])\n",
    "trade_side = np.sign(delta_pos)  # +1 buy, -1 sell, 0 none\n",
    "\n",
    "mid = s1[\"mid\"]\n",
    "ret = np.log(mid).diff().fillna(0.0)\n",
    "gross_dPnL = s1[\"pos_exec\"] * ret\n",
    "\n",
    "half_spread = (s1[\"ask\"] - s1[\"bid\"]) / 2.0\n",
    "commission_bps = 0.00005  # 0.5 bps one-way\n",
    "trade_cost = (np.abs(delta_pos) * (half_spread / mid)) + (commission_bps * (np.abs(np.sign(delta_pos))))\n",
    "trade_cost = trade_cost.fillna(0.0)\n",
    "\n",
    "net_dPnL = gross_dPnL - trade_cost\n",
    "\n",
    "s1[\"gross_equity\"] = gross_dPnL.cumsum()\n",
    "s1[\"net_equity\"]   = net_dPnL.cumsum()\n",
    "\n",
    "s1[[\"time\",\"gross_equity\",\"net_equity\"]].tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997818f8",
   "metadata": {},
   "source": [
    "## 8. Metrics (Out‑of‑Sample)\n",
    "OOS window: 2025‑09‑22 to 2025‑10‑06. Report Gross/Net P&L and annualized Sharpe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf227bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "OOS_START = pd.Timestamp('2025-09-22 00:00:00', tz='UTC')\n",
    "OOS_END   = pd.Timestamp('2025-10-06 00:00:00', tz='UTC')\n",
    "\n",
    "oos = s1[(s1[\"time\"] >= OOS_START) & (s1[\"time\"] < OOS_END)].copy()\n",
    "\n",
    "oos[\"gross_r\"] = oos[\"gross_equity\"].diff().fillna(0.0)\n",
    "oos[\"net_r\"]   = oos[\"net_equity\"].diff().fillna(0.0)\n",
    "\n",
    "def ann_sharpe(r: pd.Series) -> float:\n",
    "    mu = r.mean()\n",
    "    sd = r.std(ddof=1)\n",
    "    if sd == 0 or np.isnan(sd):\n",
    "        return float(\"nan\")\n",
    "    return (mu / sd) * math.sqrt(252*24*60*60)\n",
    "\n",
    "gross_pnl = float(oos[\"gross_r\"].sum())\n",
    "net_pnl   = float(oos[\"net_r\"].sum())\n",
    "gross_sr  = float(ann_sharpe(oos[\"gross_r\"]))\n",
    "net_sr    = float(ann_sharpe(oos[\"net_r\"]))\n",
    "trades    = int((oos[\"pos_exec\"].diff().abs() > 1e-9).sum())\n",
    "\n",
    "summary = {\n",
    "    \"OOS Gross PnL\": gross_pnl,\n",
    "    \"OOS Net PnL\": net_pnl,\n",
    "    \"OOS Gross Sharpe (ann)\": gross_sr,\n",
    "    \"OOS Net Sharpe (ann)\": net_sr,\n",
    "    \"Trades\": trades\n",
    "}\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e533ea4",
   "metadata": {},
   "source": [
    "## 9. Plot equity curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab485a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(s1[\"time\"], s1[\"gross_equity\"], label=\"Gross\")\n",
    "plt.plot(s1[\"time\"], s1[\"net_equity\"], label=\"Net\")\n",
    "plt.axvspan(pd.Timestamp('2025-09-22 00:00:00', tz='UTC'),\n",
    "            pd.Timestamp('2025-10-06 00:00:00', tz='UTC'), alpha=0.15)\n",
    "plt.title(\"Equity Curve (shaded = OOS)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d411a191",
   "metadata": {},
   "source": [
    "## 10. Email‑body bullets (auto‑fill after you run metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92ed777",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"\"\"Strategy idea (bullets):\n",
    "- Double volatility breakout on EUR/PLN ticks with EGARCH‑adaptive bands (entry k={k_entry}, exit k={k_exit}); reference = EMA.\n",
    "- Trade only during Europe/Warsaw 07:00–18:00 to avoid thin liquidity.\n",
    "- Position sizing scales inversely with forecast σ to target constant risk.\n",
    "- Execution uses bid/ask; costs = half‑spread + 0.5 bps commission (configurable).\n",
    "\n",
    "Out-of-sample results (2025‑09‑22 → 2025‑10‑06):\n",
    "- Gross P&L: {gross_pnl:.6f}\n",
    "- Net P&L:   {net_pnl:.6f}\n",
    "- Gross Sharpe (ann): {gross_sr:.2f}\n",
    "- Net Sharpe (ann):   {net_sr:.2f}\n",
    "\n",
    "Notes on correctness & bias control:\n",
    "- No look‑ahead: positions act on previous‑bar signals; OOS kept separate.\n",
    "- Parameters ≤5; avoided excessive tuning; included realistic transaction costs.\n",
    "\"\"\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
